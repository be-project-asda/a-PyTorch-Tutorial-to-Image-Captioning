{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DiverseBeamSearchCaption.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/be-project-asda/a-PyTorch-Tutorial-to-Image-Captioning/blob/development/DiverseBeamSearchCaption.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "SjD3fN6UuvsB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BDOgpjzg0vDb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QBoHPT-eu8ut",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xbwdN2kku5v7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%cd \"/content/gdrive/My Drive/data/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cBbM__xpqrQJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import json\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import skimage.transform\n",
        "import argparse\n",
        "from scipy.misc import imread, imresize\n",
        "from PIL import Image\n",
        "\n",
        "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = torch.device(\"cpu\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GK2dad12qzDT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def __add_diversity(\n",
        "        beam_seqs,\n",
        "        logprobs,\n",
        "        time,\n",
        "        group_number,\n",
        "        penalty_lambda,\n",
        "        group_size):\n",
        "    \"\"\" Adds a diversity penalty to a group of beams\n",
        "    beam_seqs       : array containing beam sequences staggered across time\n",
        "    logprobs        : log probabilities for the beam sequences\n",
        "    time            : Current time unit (not adjusted for the current group\n",
        "    group_number    : the current group number\n",
        "    penalty_lambda  : diversity penalty\n",
        "    group_size      : num_beams/num_groups\n",
        "    \"\"\"\n",
        "    local_time = time - group_number # current time for the group\n",
        "    aug_logprobs = logprobs.clone().to(device)\n",
        "    for previous_choice in range(group_number):\n",
        "        previous_decisions = beam_seqs[previous_choice][local_time]\n",
        "        for beam in range(group_size):\n",
        "            for previous_labels in range(group_size):\n",
        "                aug_logprobs[beam][previous_decisions[previous_labels]] = (\n",
        "                    penalty_lambda\n",
        "                ) # penalize previously chosen words\n",
        "    return aug_logprobs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uJ506tf2rSDg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def __beam_step(\n",
        "        logprobs,\n",
        "        aug_logprobs,\n",
        "        beam_size,\n",
        "        beam_seq,\n",
        "        beam_seq_logprobs,\n",
        "        beam_logprobs_sum,\n",
        "        rnn_state,\n",
        "        time):\n",
        "    \"\"\" Runs one step of beam search\n",
        "    logprobs         : log probabilities for beam_seqs\n",
        "    aug_logprobs     : log probabilities after penalty\n",
        "    beam_size        : Beam Size\n",
        "    beam_seq         : Tensor containing the beams\n",
        "    beam_seq_logprobs: log-probabilities of each beam sequence\n",
        "    beam_logprobs_sum: joint log probability of each beam\n",
        "    time             : time step\n",
        "    \"\"\"\n",
        "#     print(\"aug log probs size: \", aug_logprobs.shape)\n",
        "    ys, indices = torch.sort(aug_logprobs, 1, True)\n",
        "    candidates = []\n",
        "    columns = min(beam_size, len(ys[0]))\n",
        "    rows = beam_size\n",
        "#     print(beam_size)\n",
        "    if time == 1:\n",
        "        rows = 1\n",
        "\n",
        "    for column in range(columns):\n",
        "        for row in range(rows):\n",
        "            local_logprob = ys[row,column]\n",
        "            candidate_logprob = beam_logprobs_sum[row] + local_logprob\n",
        "            local_unaugmented_logprob = logprobs[row,indices[row][column]]\n",
        "            candidates.append(\n",
        "                {\n",
        "                    \"column\":indices[row][column],\n",
        "                    \"row\":row,\n",
        "                    \"prob\":candidate_logprob,\n",
        "                    \"local_logprob\":local_unaugmented_logprob\n",
        "                }\n",
        "            )\n",
        "    candidates.sort(key=lambda x: x['prob'])\n",
        "#     print(rnn_state)\n",
        "    new_state = [x.clone().to(device) for x in rnn_state]\n",
        "#     print(\"new state: \", len(new_state))\n",
        "#     print(\"rnn_state: \", len(rnn_state), type(rnn_state[0]), rnn_state[0].shape)\n",
        "#     print(\"candidates: \", len(candidates))\n",
        "\n",
        "    if time > 1:\n",
        "        beam_seq_prev = beam_seq[0:time,:].clone()\n",
        "        beam_seq_logprobs_prev = beam_seq_logprobs[0:time, :].clone()\n",
        "\n",
        "    for v_index in range(beam_size):\n",
        "        candidate = candidates[v_index]\n",
        "        candidate['kept'] = True\n",
        "        if time > 1:\n",
        "            beam_seq[0:time, v_index] = (\n",
        "                beam_seq_prev[:,candidate['row']]\n",
        "            )\n",
        "            beam_seq_logprobs[0:time, v_index] = (\n",
        "                beam_seq_logprobs_prev[:,candidate['row']]\n",
        "            )\n",
        "        for state_index in range(len(new_state)):\n",
        "#             print(\"\\n\\n\\n\",v_index)\n",
        "            new_state[state_index][v_index] = (\n",
        "                rnn_state[state_index][candidate['row']]\n",
        "            )\n",
        "\n",
        "        beam_seq[time,v_index] = candidate['column']\n",
        "        beam_seq_logprobs[time, v_index] = candidate['local_logprob']\n",
        "        beam_logprobs_sum[v_index] = candidate['prob']\n",
        "    state = new_state\n",
        "    return (\n",
        "        beam_seq,\n",
        "        beam_seq_logprobs,\n",
        "        beam_logprobs_sum,\n",
        "        state,\n",
        "        candidates\n",
        "    )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9cRig8zXrUGk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def diverse_beam_search(\n",
        "        rnn_state,\n",
        "        init_logprobs,\n",
        "        num_beams,\n",
        "        num_groups,\n",
        "        penalty_lambda,\n",
        "        seq_length,\n",
        "        end_token,\n",
        "        gen_logprobs,\n",
        "        init_token):\n",
        "    \"\"\" Performs Diverse Beam Search\n",
        "    seq_length: maximum length of sequence\n",
        "    rnn_state: states of the RNNs\n",
        "    logprobs: log-probabilities of the beams\n",
        "    num_beams: number of beams\n",
        "    num_groups: number of groups\n",
        "    penalty_lambda: value of diversity penalty\n",
        "    end_token: end-token of the vocabulary\n",
        "    gen_logprobs: function that returns\n",
        "    the states and logprobs from the RNN output\n",
        "    \"\"\"\n",
        "    beam_ratio = int(num_beams / num_groups)\n",
        "    states = []\n",
        "    beam_seqs = []\n",
        "    beam_seq_logprobs = []\n",
        "    beam_logprobs_sums = []\n",
        "    done_beams = []\n",
        "    logprobs_list=[]\n",
        "    state=[]\n",
        "    # Initialization\n",
        "    print(\"BEAM RATIO \", beam_ratio, \"\\n\", type(beam_ratio))\n",
        "\n",
        "    state = [None]*beam_ratio\n",
        "#     print(state)\n",
        "\n",
        "    for group_num in range(num_groups):\n",
        "        beam_seqs.append(torch.zeros(\n",
        "            seq_length, beam_ratio, dtype=torch.long\n",
        "        ).to(device))\n",
        "\n",
        "        beam_seq_logprobs.append(torch.zeros(\n",
        "            seq_length, beam_ratio\n",
        "        ).to(device))\n",
        "\n",
        "        beam_logprobs_sums.append(torch.zeros(\n",
        "            beam_ratio\n",
        "        ).to(device))\n",
        "\n",
        "        for k in range(beam_ratio):\n",
        "            done_beams.append([])\n",
        "        logprobs_list.append(torch.zeros(\n",
        "            beam_ratio, init_logprobs.size()[1]\n",
        "        ).to(device))\n",
        "\n",
        "        logprobs_list[group_num] = (\n",
        "            init_logprobs.clone().to(device)\n",
        "        )\n",
        "\n",
        "        for sub_beam_ix in range(beam_ratio):\n",
        "\n",
        "            beam_seqs[group_num][sub_beam_ix][0] = init_token\n",
        "            state[sub_beam_ix] = [st.clone().to(device) for st in rnn_state]\n",
        "\n",
        "#             print(state)\n",
        "\n",
        "        states.append(\n",
        "            [item.clone().to(device) for item in rnn_state]\n",
        "        )\n",
        "    # End initialization\n",
        "\n",
        "    for time in range(seq_length + num_groups):\n",
        "        for group_ix in range(num_groups):\n",
        "            if time >= group_ix and time < seq_length + group_ix:\n",
        "                logprobs = logprobs_list[group_ix]\n",
        "\n",
        "                # Suppress <UNK> tokens in the decoding\n",
        "                logprobs[:,-2] -= 1000\n",
        "#                 print(\"logprobs shape: \", logprobs.shape)\n",
        "                aug_logprobs = __add_diversity(\n",
        "                    beam_seqs,\n",
        "                    logprobs,\n",
        "                    time,\n",
        "                    group_ix,\n",
        "                    penalty_lambda,\n",
        "                    beam_ratio\n",
        "                )\n",
        "\n",
        "                # Runs one step of beam_search for the current group\n",
        "                (\n",
        "                    beam_seqs[group_ix],\n",
        "                    beam_seq_logprobs[group_ix],\n",
        "                    beam_logprobs_sums[group_ix],\n",
        "                    states[group_ix],\n",
        "                    candidates_group\n",
        "                ) = __beam_step(\n",
        "                        logprobs,\n",
        "                        aug_logprobs,\n",
        "                        beam_ratio,\n",
        "                        beam_seqs[group_ix],\n",
        "                        beam_seq_logprobs[group_ix],\n",
        "                        beam_logprobs_sums[group_ix],\n",
        "                        states[group_ix],\n",
        "                        time - group_ix\n",
        "                )\n",
        "\n",
        "                for beam_ix in range(beam_ratio):\n",
        "                    is_first_end_token = (\n",
        "                        (\n",
        "                            beam_seqs[group_ix][:,beam_ix][time-group_ix] == \\\n",
        "                         end_token\n",
        "                        ) and (\n",
        "                            torch.eq(\n",
        "                                beam_seqs[group_ix][:,beam_ix],\n",
        "                                end_token\n",
        "                            ).sum() == 0\n",
        "                        )\n",
        "                    )\n",
        "\n",
        "                    final_time_wo_end = (\n",
        "                        (\n",
        "                            time == seq_length + group_ix\n",
        "                        ) and (\n",
        "                            torch.eq(\n",
        "                                beam_seqs[group_ix][:,beam_ix],\n",
        "                                end_token\n",
        "                            ).sum() == 0\n",
        "                        )\n",
        "                    )\n",
        "\n",
        "                    if is_first_end_token or final_time_wo_end:\n",
        "                        print(\"End token reached!\")\n",
        "                        input()\n",
        "                        final_beam = {\n",
        "                            \"seq\": beam_seqs[group_ix][:,beam_ix].clone(),\n",
        "                            \"logps\": beam_seq_logprobs[group_ix]\\\n",
        "                                [:,beam_ix].clone(),\n",
        "                            \"logp\": beam_seq_logprobs[group_ix][:,beam_ix]\\\n",
        "                                .sum(),\n",
        "                            \"aug_logp\": beam_logprobs_sums[group_ix][beam_ix]\n",
        "                        }\n",
        "                        final_beam[\"candidate\"] = candidates_group[beam_ix]\n",
        "                        done_beams[beam_ix] = final_beam\n",
        "\n",
        "                    if is_first_end_token:\n",
        "                        beam_logprobs_sums[group_ix][beam_ix] = -1000\n",
        "\n",
        "                inpt = beam_seqs[group_ix][time - group_ix]\n",
        "                output = gen_logprobs(inpt, states[group_ix])\n",
        "#                 print(\"Type of output: {}\".format(type(output)))\n",
        "#                 for indexofiteminoutput, iteminoutput in enumerate(output):\n",
        "#                     print(\"type of output[{}]: {}\".format(\n",
        "#                         indexofiteminoutput, type(iteminoutput)\n",
        "#                     ))\n",
        "#                     print(\"Shape of output[{}]: {}\".format(\n",
        "#                         indexofiteminoutput, iteminoutput.size()\n",
        "#                     ))\n",
        "#                 print(\"Shape of Last element in output: {}\".format(output[-1].size()))\n",
        "                logprobs_list[group_ix] = output[-1].clone()\n",
        "                temp_state = [\n",
        "                    output[i].clone().to(device)\n",
        "                    for i\n",
        "                    in range(len(output)-1)\n",
        "                ]\n",
        "                states[group_ix] = [st.clone().to(device) for st in temp_state]\n",
        "\n",
        "    outputs = []\n",
        "    for i in range(num_groups):\n",
        "        curr_outs = [[] for s in range(beam_ratio)]\n",
        "        group = beam_seqs[i]\n",
        "        print(group.size())\n",
        "        for j in range(group.size()[1]):\n",
        "            for k in range(group.size()[0]):\n",
        "                curr_outs[j].append(rev_word_map[int(group[k,j])])\n",
        "        outputs.extend(curr_outs)\n",
        "    input()\n",
        "    print(outputs)\n",
        "    input()\n",
        "    for i in range(num_groups):\n",
        "        done_beams[i].sort(key=lambda x:x['aug_logp'])\n",
        "        done_beams[i] = done_beams[i][0:beam_ratio]\n",
        "    return done_beams\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-mSMICQCrcI5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def caption_image_beam_search(\n",
        "        encoder,\n",
        "        decoder,\n",
        "        image_path,\n",
        "        word_map,\n",
        "        beam_size,\n",
        "        num_groups,\n",
        "        penalty):\n",
        "    \"\"\"Reads an image and captions it with beam search.\n",
        "    param encoder: encoder model\n",
        "    param decoder: decoder model\n",
        "    param image_path: path to image\n",
        "    param word_map: word map\n",
        "    param beam_size: number of sequences to consider at each decode-step\n",
        "    return: caption, weights for visualization\n",
        "    \"\"\"\n",
        "\n",
        "    k = beam_size\n",
        "    beam_ratio = int(k/num_groups)\n",
        "    vocab_size = len(word_map)\n",
        "\n",
        "    # Read image and process\n",
        "    img = imread(image_path)\n",
        "\n",
        "    if len(img.shape) == 2:\n",
        "        img = img[:, :, np.newaxis]\n",
        "        img = np.concatenate([img, img, img], axis=2)\n",
        "    img = imresize(img, (256, 256))\n",
        "    img = img.transpose(2, 0, 1)\n",
        "    img = img / 255.\n",
        "    img = torch.FloatTensor(img)\n",
        "    img = img.to(device)\n",
        "    normalize = transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "    transform = transforms.Compose([normalize])\n",
        "    image = transform(img)  # (3, 256, 256)\n",
        "\n",
        "    # Encode\n",
        "    image = img.unsqueeze(0)  # (1, 3, 256, 256)\n",
        "    encoder_out = encoder(image)\n",
        "                # (1, enc_image_size, enc_image_size, encoder_dim)\n",
        "    enc_image_size = encoder_out.size(1)\n",
        "    encoder_dim = encoder_out.size(3)\n",
        "\n",
        "    # Flatten encoding\n",
        "    encoder_out = encoder_out.view(1, -1, encoder_dim)\n",
        "    # (1, num_pixels, encoder_dim)\n",
        "\n",
        "    num_pixels = encoder_out.size(1)\n",
        "\n",
        "    # We'll treat the problem as having a batch size of k\n",
        "    encoder_out = encoder_out.expand(\n",
        "        beam_ratio,\n",
        "        num_pixels,\n",
        "        encoder_dim\n",
        "    )  # (k, num_pixels, encoder_dim)\n",
        "\n",
        "    # Tensor to store top k previous words at each step;\n",
        "    #now they're just <start>\n",
        "    # k_prev_words = torch.LongTensor(\n",
        "    #     [[word_map['<start>']]]\n",
        "    # ).to(device)  # (k, 1)\n",
        "\n",
        "    # init_logprobs = [([None] * beam_ratio)*num_groups]\n",
        "\n",
        "    h, c = decoder.init_hidden_state(encoder_out)\n",
        "    print(\"h: \", h.shape)\n",
        "    print(\"c: \", c.shape)\n",
        "\n",
        "    def generate_log_probabilities(inputs, states):\n",
        "        h_ = states[0]\n",
        "        c_ = states[1]\n",
        "        embeddings = decoder.embedding(inputs).squeeze(1)\n",
        "        awe, alpha = decoder.attention(encoder_out, h_)\n",
        "#         print(\"awe before gate*awe: \" + str(awe.shape))\n",
        "        gate = decoder.sigmoid(decoder.f_beta(h_))\n",
        "        awe = gate * awe\n",
        "#         print(\"awe after gate*awe: \" + str(awe.shape))\n",
        "        \n",
        "#         print(\"embeddings: \"+ str(embeddings.shape))\n",
        "#         print(\"concatenated: \",torch.cat([embeddings, awe], dim=1).size())\n",
        "        h_, c_ = decoder.decode_step(\n",
        "            torch.cat([embeddings, awe], dim=1),\n",
        "            (h_, c_)\n",
        "        )  #tried something\n",
        "        scores = F.log_softmax(decoder.fc(h_), dim=1)\n",
        "        return h_, c_, scores\n",
        "\n",
        "    init_seq = torch.LongTensor([[word_map['<start>']]]*beam_ratio).to(device)\n",
        "#     print(\"Sizeof Init_Seq: {}\".format(init_seq.size()))\n",
        "    # init_seq = torch.LongTensor([word_map['<start>']]*beam_ratio).to(device).unsqueeze(0)\n",
        "    h,c,init_logprobs = generate_log_probabilities(init_seq, [h,c])\n",
        "\n",
        "    done_beams = diverse_beam_search(\n",
        "        rnn_state=[h, c],\n",
        "        init_logprobs=init_logprobs,\n",
        "        num_beams=k,\n",
        "        num_groups=num_groups,\n",
        "        penalty_lambda=penalty,\n",
        "        seq_length=50,\n",
        "        end_token=word_map['<end>'],\n",
        "        gen_logprobs=generate_log_probabilities,\n",
        "        init_token=word_map['<start>']\n",
        "    )\n",
        "    # s is a number less than or equal to k,\n",
        "    #because sequences are removed from this process once they hit <end>\n",
        "    for beam in done_beams:\n",
        "        print(type(beam))\n",
        "        print(beam)\n",
        "    seq = [beam['seq'] for beam in done_beams]\n",
        "    return seq\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hlNaW1G-tXDy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_path = \"./BEST_checkpoint_coco_5_cap_per_img_5_min_word_freq.pth.tar\"\n",
        "word_map_path = \"./WORDMAP_coco_5_cap_per_img_5_min_word_freq.json\"\n",
        "image_path = \"./DOG-ssssss-dogs-25606625-1024-768.jpg\"\n",
        "beam_size = 8\n",
        "num_groups = 4\n",
        "_lambda = 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VGJHOeQNzyS0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rev_word_map[9489]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZipMdnflwjWB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(model_path)\n",
        "decoder = checkpoint['decoder']\n",
        "decoder = decoder.to(device)\n",
        "decoder.eval()\n",
        "encoder = checkpoint['encoder']\n",
        "encoder = encoder.to(device)\n",
        "encoder.eval()\n",
        "\n",
        "with open(word_map_path, 'r') as j:\n",
        "    word_map = json.load(j)\n",
        "rev_word_map = {v: k for k, v in word_map.items()}\n",
        "seqs = caption_image_beam_search(\n",
        "        encoder,\n",
        "        decoder,\n",
        "        image_path,\n",
        "        word_map,\n",
        "        beam_size=beam_size,\n",
        "        num_groups=num_groups,\n",
        "        penalty=_lambda\n",
        "    )\n",
        "for seq in seqs:\n",
        "    words = [rev_word_map[ind] for ind in seq]\n",
        "    print(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1WKegyYdFPOc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a = torch.LongTensor([[1,2],[3,4],[5,6]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YOC8pfyrLLf0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "int(a[2,1])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}